{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "p = print\n",
    "\n",
    "#pls take note of version\n",
    "#numpy 1.17.3\n",
    "#pandas 1.0.3\n",
    "#sklearn 0.21.3\n",
    "\n",
    "dollar = pd.read_csv('../Sample_data/dollar_bars.txt', \n",
    "                 sep=',', \n",
    "                 header=0, \n",
    "                 parse_dates = True, \n",
    "                 index_col=['date_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Support us on Patreon: https://www.patreon.com/HudsonThames\n",
      "\n",
      "MlFinLab needs you! We need your help for us to keep on maintaining and implementing academic research based on \n",
      "financial machine learning (for open-source). In order for us to continue we need to raise $4000 of monthly donations\n",
      "via Patreon - by December 2020. If we can't reach our goal, we will need to adopt more of a paid for service. We thought\n",
      "that the best and least impactful course of action (should we not reach our goal) is to leave the package as open-source\n",
      "but to make the documentation (ReadTheDocs) a paid for service. This is the ultimate litmus test, if the package is a \n",
      "value add, then we need the community to help us keep it going.\n",
      "\n",
      "Our road map for 2020 is to implement the text book: Machine Learning for Asset Managers by Marcos Lopez de Prado, \n",
      "as well as a few papers from the Journal of Financial Data Science. We are hiring a full time developer for 3 months \n",
      "to help us reach our goals. The money that you, our sponsors, contribute will go directly to paying salaries and other \n",
      "expenses such as journal subscriptions and data. \n",
      "\n",
      "We need your help to continue maintaining and developing this community. Thank you for using our package and we \n",
      "invite you to join our slack channel using the following link:\n",
      "https://join.slack.com/t/mlfinlab/shared_invite/zt-c62u9gpz-VFc13j6da~UVg3DkV7~RjQ\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from mlfinlab.sampling import concurrent\n",
    "from mlfinlab.sampling import bootstrapping\n",
    "\n",
    "from mlfinlab.filters import filters\n",
    "from mlfinlab.labeling import labeling\n",
    "\n",
    "from mlfinlab.util import multiprocess\n",
    "from mlfinlab.util import volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol = volatility.get_daily_vol(close=dollar['close'], lookback=50)\n",
    "cusum_events = filters.cusum_filter(dollar['close'], threshold=vol.mean())\n",
    "vertical_barriers = labeling.add_vertical_barrier(cusum_events, dollar['close'], num_days=1)\n",
    "triple_barrier_events = labeling.get_events(close=dollar['close'],\n",
    "                                               t_events=cusum_events,\n",
    "                                               pt_sl=[1, 1],\n",
    "                                               target=vol,\n",
    "                                               min_ret=0.01,\n",
    "                                               num_threads=1,\n",
    "                                               vertical_barrier_times=vertical_barriers,\n",
    "                                               side_prediction=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-15 20:00:33.117615 50.0% num_concurrent_events done after 0.13 minutes. Remaining 0.13 minutes.\r",
      "2020-05-15 20:00:33.132666 100.0% num_concurrent_events done after 0.13 minutes. Remaining 0.0 minutes.\n"
     ]
    }
   ],
   "source": [
    "num_threads = 2\n",
    "num_conc_events = multiprocess.mp_pandas_obj(concurrent.num_concurrent_events, \n",
    "                                             ('molecule', triple_barrier_events.index), \n",
    "                                             num_threads, \n",
    "                                             close_series_index=dollar['close'].index, \n",
    "                                             label_endtime=triple_barrier_events['t1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_conc_events = num_conc_events.loc[~num_conc_events.index.duplicated(keep='last')]\n",
    "num_conc_events = num_conc_events.reindex(dollar['close'].index).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-15 20:00:42.317896 100.0% num_concurrent_events done after 0.14 minutes. Remaining 0.0 minutes.\n",
      "2020-05-15 20:00:51.201344 100.0% _get_average_uniqueness done after 0.13 minutes. Remaining 0.0 minutes.\n"
     ]
    }
   ],
   "source": [
    "av_unique = concurrent.get_av_uniqueness_from_triple_barrier(triple_barrier_events, \n",
    "                                                  close_series = dollar['close'], \n",
    "                                                  num_threads = num_threads)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-09 17:13:19.851</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-15 13:45:55.324</th>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-15 14:39:34.621</th>\n",
       "      <td>0.938776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-30 10:09:09.112</th>\n",
       "      <td>0.474747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-30 14:48:27.262</th>\n",
       "      <td>0.358156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-11-09 16:12:17.063</th>\n",
       "      <td>0.232258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-11-09 16:37:40.228</th>\n",
       "      <td>0.364966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-11-10 05:25:08.903</th>\n",
       "      <td>0.548110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-11-10 15:08:22.780</th>\n",
       "      <td>0.531481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-11-10 15:37:05.621</th>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>261 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               tW\n",
       "2015-01-09 17:13:19.851  1.000000\n",
       "2015-01-15 13:45:55.324  0.727273\n",
       "2015-01-15 14:39:34.621  0.938776\n",
       "2015-01-30 10:09:09.112  0.474747\n",
       "2015-01-30 14:48:27.262  0.358156\n",
       "...                           ...\n",
       "2016-11-09 16:12:17.063  0.232258\n",
       "2016-11-09 16:37:40.228  0.364966\n",
       "2016-11-10 05:25:08.903  0.548110\n",
       "2016-11-10 15:08:22.780  0.531481\n",
       "2016-11-10 15:37:05.621  0.333333\n",
       "\n",
       "[261 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "av_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#num_conc_events.value_counts()\n",
    "\n",
    "df0 = pd.DataFrame(index = num_conc_events.index).assign(volatility = vol, num_conc_events = num_conc_events)\n",
    "df0 = df0.drop_duplicates().dropna()\n",
    "df0[['volatility', 'num_conc_events']].plot(secondary_y='volatility', figsize=(10,8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,8))\n",
    "df1 = df0.groupby(num_conc_events, axis = 0).mean() # Try piecewise estimate\n",
    "plt.plot(df0['num_conc_events'], df0['volatility'], '.', df1['num_conc_events'], df1['volatility'], '-')\n",
    "plt.axhline(y = 0.015, c='r', ls='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lagrange Multiplier tests for autocorrelation**\n",
    "\n",
    "H0: the sequence was produced in a random manner.\n",
    "    \n",
    "H1: the sequence was not produced in a random manner.\n",
    "\n",
    "If pval < 0.05 (Random: Accept H0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.sandbox.stats import diagnostic\n",
    "\n",
    "pval = diagnostic.acorr_lm(av_unique.squeeze(), maxlag = 1, autolag = 'AIC')[1]\n",
    "p(\"pvalue for LM test: {0}\".format(pval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Based on the below ACF, autocorr is considered significant (No sharp drop, nlag may go up to 100)\n",
    "\n",
    "pd.plotting.autocorrelation_plot(av_unique.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "av_unique['tW'].plot(kind = 'hist', figsize=(10,8), title = 'Average Uniqueness of t1 events')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Based on scatter graph**\n",
    "\n",
    "Using mean as an estimate to plot a piecewise function graph, volatility and concurrency has a weak positive relationship.\n",
    "\n",
    "Most mean estimate value per concurrenct event has never crossed medium frequency.\n",
    "\n",
    "A spike in volatility will produce concurrent events however concurrent events may not cause as much volatility. \n",
    "\n",
    "Hence causality relationship.\n",
    "\n",
    "**Based on LM autocorr test and ACF plot**\n",
    "\n",
    "Average uniqueness of data set is statistically significant at autocorr 1.\n",
    "\n",
    "Since data sample's average uniqueness is a derivation of weight distribution from concurrent event (With causality relationship with volatility).\n",
    "\n",
    "More volatility => More concurrent event => Reduced average uniqueness (More imbalance) => Increased autocorrelation => More residual noise\n",
    "\n",
    "The key implication where time-series is concerned, stationarity may be affected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 50\n",
    "\n",
    "def bband(data: pd.Series, span0: int = 50, width: int = 1):\n",
    "    '''\n",
    "    Basic bollinger band\n",
    "    \n",
    "    params: DataFrame => entire dataframe which close price resides\n",
    "    params: int => span0 is how many to roll\n",
    "    params: int => width to set \n",
    "    '''\n",
    "    \n",
    "    ma = data.ewm(span = span0).mean()\n",
    "    std = data.ewm(span = span0).std()\n",
    "    \n",
    "    upper = ma + (std * width)\n",
    "    lower = ma + (std * width)\n",
    "    \n",
    "    return ma, upper, lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dollar['ma'], dollar['upper'], dollar['lower'] = bband(dollar['close'], span0 = window, width = 2)\n",
    "dollar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dollar\n",
    "data['side'] = np.nan \n",
    "\n",
    "long_signals = (data['close'] <= data['lower']) \n",
    "short_signals = (data['close'] >= data['upper']) \n",
    "\n",
    "data.loc[long_signals, 'side'] = 1\n",
    "data.loc[short_signals, 'side'] = -1\n",
    "\n",
    "print(data.side.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = data.copy()\n",
    "\n",
    "# Drop the NaN values from our data set\n",
    "data.dropna(axis=0, how='any', inplace=True)\n",
    "print(data.side.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute daily volatility\n",
    "daily_vol = volatility.get_daily_vol(close=data['close'], lookback=50)\n",
    "\n",
    "# Apply Symmetric CUSUM Filter and get timestamps for events\n",
    "# Note: Only the CUSUM filter needs a point estimate for volatility\n",
    "cusum_events = filters.cusum_filter(data['close'], threshold=daily_vol.mean() * 0.1)\n",
    "\n",
    "# Compute vertical barrier\n",
    "vertical_barriers = labeling.add_vertical_barrier(t_events=cusum_events, close=data['close'], num_days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_sl = [0, 2]\n",
    "min_ret = 0.0005\n",
    "triple_barrier_events = labeling.get_events(close=data['close'],\n",
    "                                            t_events=cusum_events,\n",
    "                                            pt_sl=pt_sl,\n",
    "                                            target=daily_vol,\n",
    "                                            min_ret=min_ret,\n",
    "                                            num_threads=2,\n",
    "                                            vertical_barrier_times=vertical_barriers,\n",
    "                                            side_prediction=data['side'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Averge uniqueness\n",
    "avg_uniqueness = concurrent.get_av_uniqueness_from_triple_barrier(triple_barrier_events, data['close'], num_threads=1)\n",
    "p(avg_uniqueness.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labeling.get_bins(triple_barrier_events, data['close'])\n",
    "labels.side.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log Returns\n",
    "raw_data['log_ret'] = np.log(raw_data['close']).diff()\n",
    "\n",
    "# Volatility\n",
    "window_stdev = 50\n",
    "raw_data['volatility'] = raw_data['log_ret'].rolling(window=window_stdev, min_periods=window_stdev, center=False).std()\n",
    "\n",
    "# Serial Correlation (Takes about 4 minutes)\n",
    "window_autocorr = 50\n",
    "\n",
    "raw_data['autocorr_1'] = raw_data['log_ret'].rolling(window=window_autocorr, min_periods=window_autocorr, center=False).apply(lambda x: x.autocorr(lag=1), raw=False)\n",
    "raw_data['autocorr_2'] = raw_data['log_ret'].rolling(window=window_autocorr, min_periods=window_autocorr, center=False).apply(lambda x: x.autocorr(lag=2), raw=False)\n",
    "raw_data['autocorr_3'] = raw_data['log_ret'].rolling(window=window_autocorr, min_periods=window_autocorr, center=False).apply(lambda x: x.autocorr(lag=3), raw=False)\n",
    "raw_data['autocorr_4'] = raw_data['log_ret'].rolling(window=window_autocorr, min_periods=window_autocorr, center=False).apply(lambda x: x.autocorr(lag=4), raw=False)\n",
    "raw_data['autocorr_5'] = raw_data['log_ret'].rolling(window=window_autocorr, min_periods=window_autocorr, center=False).apply(lambda x: x.autocorr(lag=5), raw=False)\n",
    "\n",
    "# Get the various log -t returns\n",
    "raw_data['log_t1'] = raw_data['log_ret'].shift(1)\n",
    "raw_data['log_t2'] = raw_data['log_ret'].shift(2)\n",
    "raw_data['log_t3'] = raw_data['log_ret'].shift(3)\n",
    "raw_data['log_t4'] = raw_data['log_ret'].shift(4)\n",
    "raw_data['log_t5'] = raw_data['log_ret'].shift(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get autocorrelation residual\n",
    "from statsmodels.tsa.arima_model import ARMA\n",
    "def ar_model_resid(data: pd.DataFrame, nlags: int = 3):\n",
    "    for i in np.arange(nlags):\n",
    "        ar_model = ARMA(data['close'], order=(i,0)).fit().resid\n",
    "        data['ar_resid'+ str(i)] = ar_model\n",
    "    return data\n",
    "\n",
    "raw_data = ar_model_resid(raw_data, nlags = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = raw_data.reindex(labels.index).dropna()\n",
    "y = labels['bin'].iloc[6:]\n",
    "\n",
    "# Remove only those I did not used\n",
    "X.drop(['open', 'high', 'low', 'cum_vol', 'cum_dollar', 'cum_ticks'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training, validation and test sets\n",
    "X_training_test = X\n",
    "y_training_test = y\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_training_test, y_training_test, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([y_train, X_train], axis=1, join='inner')\n",
    "train_df['bin'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training data\n",
    "y_train = train_df['bin']\n",
    "X_train= train_df.loc[:, train_df.columns != 'bin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract parameters, due to the number of features it can take up to 5 mins\n",
    "\n",
    "parameters = {'max_depth':[3, 4, 5, 7, 8, 9], #need to skip 6 if not ROC v weird recommend to start with 3\n",
    "              'n_estimators':[25, 50, 100, 150, 250, 500], # if you want to have high OOB increase your estimators\n",
    "              'random_state':[42]} # if you want to perform grid search random state has to be fixed\n",
    "\n",
    "def perform_grid_search(X_data, y_data):\n",
    "    rf = RandomForestClassifier(criterion='entropy')\n",
    "    \n",
    "    clf = GridSearchCV(rf, parameters, cv=4, scoring='roc_auc', n_jobs=3)\n",
    "    \n",
    "    clf.fit(X_data, y_data)\n",
    "    \n",
    "    print(clf.cv_results_['mean_test_score'])\n",
    "    \n",
    "    return clf.best_params_['n_estimators'], clf.best_params_['max_depth']\n",
    "\n",
    "# best parameter to be used\n",
    "\n",
    "n_estimators, max_depth = perform_grid_search(X_train, y_train)\n",
    "c_random_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(n_estimators, max_depth, c_random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Classifer: OOB Score\n",
    "\n",
    "Based on \"Best\" parameters from grid search CV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Model\n",
    "rf = RandomForestClassifier(max_depth = max_depth, \n",
    "                            n_estimators = n_estimators, \n",
    "                            oob_score = True, #set to True\n",
    "                            criterion = 'entropy', \n",
    "                            random_state = c_random_state)\n",
    "\n",
    "rf.fit(X_train, y_train.values.ravel())\n",
    "print(\"Out-of-bag Accuracy (OOB Score): {:.6f}\".format(rf.oob_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KFolds Split: KFolds Accuracy\n",
    "\n",
    "Cross-Validation KFolds to compare, without shuffling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-fold\n",
    "no_of_folds = 5\n",
    "kfold = KFold(shuffle=False, random_state=1, n_splits=no_of_folds)\n",
    "\n",
    "accuracy_array = np.zeros(no_of_folds)\n",
    "i = 0\n",
    "for train_index, test_index in kfold.split(X_training_test):\n",
    "    # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    rf.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "    y_pred_rf = rf.predict_proba(X_test)[:, 1]\n",
    "    y_pred = rf.predict(X_test)\n",
    "    accuracy_array[i] = accuracy_score(y_test, y_pred)\n",
    "    i += 1\n",
    "    \n",
    "print(\"Mean KFold accuracy: {:.6f}\".format(np.mean(accuracy_array)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OOB Score vs Mean KFold Accuracy**\n",
    "\n",
    "Mean KFold accuracy: 0.514474\n",
    "Out-of-bag Accuracy (OOB Score): 0.582547\n",
    "    \n",
    "OOB score is about 7% higher compared to Mean KFold Accuracy score, this is quite significant.\n",
    "\n",
    "Quoted in section 4.5 of AFML, page 62 states, \"incorrect assuming IID draws leads to oversampling, when sample with replacement (bootstrap default = True)\".\n",
    "\n",
    "Quoted in section 4.5 of AFML, page 63 states, \"random sampling will make out-of-bag examples very similar to in-the-bag ones, the OOB accuracy would be grossly inflated\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_decay(tw, clf_last_w=1.):\n",
    "    # apply piecewise-linear decay to observed uniqueness (tw)\n",
    "    # newest observation gets weight=1, oldest observation gets weight=clf_last_w\n",
    "    clf_w = tw.sort_index().cumsum()\n",
    "    if clf_last_w >= 0:\n",
    "        slope = (1. - clf_last_w) / clf_w.iloc[-1]\n",
    "    else:\n",
    "        slope = 1. /((clf_last_w + 1) * clf_w.iloc[-1])\n",
    "    \n",
    "    const = 1. - slope * clf_w.iloc[-1]\n",
    "    clf_w = const + slope * clf_w\n",
    "    clf_w[clf_w < 0] = 0\n",
    "    #print(\"Constant\\n{0}\\nSlope\\n{1}\\n\".format(const, slope))\n",
    "    return clf_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w0 = get_time_decay(av_unique, 1.0)\n",
    "w1 = get_time_decay(av_unique, 0.75)\n",
    "w2 = get_time_decay(av_unique, 0.5)\n",
    "w3 = get_time_decay(av_unique, -0.25)\n",
    "w4 = get_time_decay(av_unique, -0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decay_df = pd.DataFrame(index=av_unique.index).assign(\n",
    "                              decay_1=w0,\n",
    "                              decay_2=w1,\n",
    "                              decay_3=w2,\n",
    "                              decay_4=w3,\n",
    "                              decay_5=w4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decay_df[['decay_1', 'decay_2', 'decay_3', 'decay_4', 'decay_5']].plot()\n",
    "\n",
    "# Weirdest piecewise linear i ever seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Model\n",
    "rf = RandomForestClassifier(max_depth=max_depth, n_estimators=n_estimators, oob_score=True,\n",
    "                            criterion='entropy', random_state=c_random_state)\n",
    "# Create training data\n",
    "y_train = train_df['bin']\n",
    "X_train= train_df.loc[:, train_df.columns != 'bin']\n",
    "rf.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "print(rf)\n",
    "rf.fit(X_train, y_train.values.ravel())\n",
    "print(\"Out-of-bag Accuracy (OOB Score): {:.6f}\".format(rf.oob_score_))\n",
    "\n",
    "# Performance Metrics\n",
    "y_pred_rf = rf.predict_proba(X_train)[:, 1]\n",
    "y_pred = rf.predict(X_train)\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_train, y_pred_rf)\n",
    "print(classification_report(y_train, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(y_train, y_pred))\n",
    "\n",
    "print('')\n",
    "print(\"Accuracy\")\n",
    "print(accuracy_score(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Meta-label\n",
    "# Performance Metrics\n",
    "y_pred_rf = rf.predict_proba(X_test)[:, 1]\n",
    "y_pred = rf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print('')\n",
    "print(\"Accuracy\")\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(max_depth=max_depth, \n",
    "                            n_estimators=n_estimators, \n",
    "                            oob_score=True,\n",
    "                            class_weight='balanced', #just include class_weight = 'balance_subsample'\n",
    "                            criterion='entropy', \n",
    "                            random_state=c_random_state)\n",
    "print(rf)\n",
    "rf.fit(X_train, y_train.values.ravel())\n",
    "print(\"Out-of-bag Accuracy (OOB Score): {:.6f}\".format(rf.oob_score_)) #OOB score increase signifcantly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance Metrics\n",
    "y_pred_rf = rf.predict_proba(X_train)[:, 1]\n",
    "y_pred = rf.predict(X_train)\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_train, y_pred_rf)\n",
    "print(classification_report(y_train, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(y_train, y_pred))\n",
    "\n",
    "print('')\n",
    "print(\"Accuracy\")\n",
    "print(accuracy_score(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Meta-label\n",
    "# Performance Metrics\n",
    "y_pred_rf = rf.predict_proba(X_test)[:, 1]\n",
    "y_pred = rf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print('')\n",
    "print(\"Accuracy\")\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
